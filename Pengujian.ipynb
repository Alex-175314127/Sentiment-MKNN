{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models.MKNN import ModifiedKNN\n",
    "import neattext.functions as nfx\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Twitter_fresh/twitter_crawling.csv',encoding='latin1', usecols=['date','text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding(Text):\n",
    "    Text = Text.lower()\n",
    "    return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(casefolding)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc_clean(Text):\n",
    "        Text = nfx.remove_urls(Text)\n",
    "        Text = nfx.remove_punctuations(Text)\n",
    "        Text = nfx.remove_emojis(Text)\n",
    "        Text = nfx.remove_special_characters(Text)\n",
    "        Text = nfx.remove_numbers(Text)\n",
    "        return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(punc_clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(Text):\n",
    "        return word_tokenize(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(word_tokenize_wrapper)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_norm(tweets):\n",
    "    word_dict = pd.read_csv('data/indonesia_slangWords.csv')\n",
    "    norm_word_dict = {}\n",
    "    for index, row in word_dict.iterrows():\n",
    "        if row[0] not in norm_word_dict:\n",
    "            norm_word_dict[row[0]] = row[1]\n",
    "    return [norm_word_dict[term] if term in norm_word_dict else term for term in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(word_norm)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(Text):\n",
    "    stopW = stopwords.words('indonesian', 'english')\n",
    "    sw = pd.read_csv('data/stopwordbahasa.csv')\n",
    "    stopW.extend(sw)\n",
    "    remove_sw = ' '.join(Text)\n",
    "    clean_sw = [word for word in remove_sw.split() if word.lower() not in stopW]\n",
    "    return clean_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(remove_stopword)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indo_stem(Text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    result = []\n",
    "    for w in Text:\n",
    "        result.append(stemmer.stem(w))\n",
    "        result.append(\" \")\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(indo_stem)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_analysis():\n",
    "    df = pd.read_csv('Twitter_fresh/Clean Data/Twitter_clean_2000.csv', encoding='utf-8')\n",
    "\n",
    "    # LexiconVader dengan custom Lexicon(bahasa indonesia)\n",
    "    sia1A, sia1B = SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer()\n",
    "    senti = SentimentIntensityAnalyzer()\n",
    "    # Hapus Default lexicon VADER\n",
    "    sia1A.lexicon.clear()\n",
    "    sia1B.lexicon.clear()\n",
    "    senti.lexicon.clear()\n",
    "\n",
    "    # Read custom Lexicon Bahasa Indonesia\n",
    "    data1A = open('data/lexicon_sentimen_negatif.txt', 'r').read()\n",
    "    data1B = open('data/lexicon_sentimen_positif.txt', 'r').read()\n",
    "    data_senti = open('data/sentiwords_id.txt', 'r').read()\n",
    "    \n",
    "    # convert lexicon to dictonary\n",
    "    insetNeg = json.loads(data1A)\n",
    "    insetPos = json.loads(data1B)\n",
    "    sa = json.loads(data_senti)\n",
    "\n",
    "    # update lexicon vader with custom lexicon (b.indo)\n",
    "    sia1A.lexicon.update(insetNeg)\n",
    "    sia1B.lexicon.update(insetPos)\n",
    "    senti.lexicon.update(sa)\n",
    "\n",
    "    # method untuk cek apa sentimen pos,neg,neu\n",
    "    def is_positive_inset(Text: str) -> bool:\n",
    "        return sia1A.polarity_scores(Text)[\"compound\"] + sia1B.polarity_scores(Text)[\"compound\"] >= 0.05\n",
    "    \n",
    "    tweets = df['text'].to_list()\n",
    "\n",
    "    with open('output/Sentiment-result.txt', 'w+') as f:\n",
    "        for tweet in tweets:\n",
    "            label = \"Positive\" if is_positive_inset(tweet) else \"Negative\"\n",
    "            f.write(str(label + \"\\n\"))\n",
    "\n",
    "    sen = pd.read_csv('output/Sentiment-result.txt', names=['Sentiment'])\n",
    "    df = df.join(sen)\n",
    "\n",
    "    ## Save clean Dataset\n",
    "    #df.to_csv('CleanText_Sentiment.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result = Sentiment_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    1560\n",
       "Positive     440\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_result['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result.to_csv('output/Sentiment_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models Algorithm M KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from heapq import nsmallest as nMin\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_word_weight(vect, word_weight):\n",
    "    feature_name = np.array(vect.get_feature_names_out())\n",
    "    data = word_weight.data\n",
    "    indptr = word_weight.indptr\n",
    "    indices = word_weight.indices\n",
    "    n_docs = word_weight.shape[0]\n",
    "\n",
    "    word_weght_list = []\n",
    "    for i in range(n_docs):\n",
    "        doc = slice(indptr[i], indptr[i + 1])\n",
    "        count, idx = data[doc], indices[doc]\n",
    "        feature = feature_name[idx]\n",
    "        word_weght_dict = dict(dict(zip(feature, count)))\n",
    "        word_weght_list.append(word_weght_dict)\n",
    "    word_weght_df = pd.DataFrame(word_weght_list)\n",
    "    word_weght_df = word_weght_df.fillna(0)\n",
    "    return word_weght_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(decode_error=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfeatures = sentiment_result.text\n",
    "Xfeatures = tf.fit_transform(Xfeatures)\n",
    "df_tfidf = TFIDF_word_weight(tf, Xfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.to_csv('output/tfidf_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jarak_euc(x,y):\n",
    "    return euclidean_distances(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = jarak_euc(Xfeatures,Xfeatures)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(X_train)\n",
    "dd.to_csv('euc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_value = 9 # 1 - 25\n",
    "X = sentiment_result['text'].values\n",
    "y = sentiment_result['Sentiment'].values\n",
    "fold_i = 1\n",
    "fold_n = 10 # 3 5 7 10\n",
    "sum_accuracy = 0\n",
    "kfold = KFold(fold_n, shuffle=True, random_state=42)\n",
    "enc = LabelEncoder()\n",
    "fol = []\n",
    "acc, rc, pr, f1 = [], [], [], []\n",
    "\n",
    "for train_index, test_index in tqdm(kfold.split(X)):\n",
    "    fol.append(fold_i)\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    svf = open('output/ResultX.txt', 'w')\n",
    "    sv_text = '\\n'.join(str(item) for item in X_test).replace(\"   \",\" \")\n",
    "    svf.write(sv_text)\n",
    "    svY = open ('output/y_train.txt', 'w')\n",
    "    svY.write('\\n'.join(str(item) for item in y_train))\n",
    "\n",
    "    #TFIDF\n",
    "    tf = TfidfVectorizer(decode_error=\"replace\")\n",
    "    X_train = tf.fit_transform(X_train)\n",
    "    X_test = tf.transform(X_test)\n",
    "    \n",
    "    y_train = enc.fit_transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "\n",
    "    # Algorithm\n",
    "    clf = ModifiedKNN(k_value)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred, jarak = clf.predict(X_test)\n",
    "    neigbor_index = clf.get_neigbors(X_test)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    #tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    accuracy = accuracy_score(y_test, pred)*100\n",
    "    precision = precision_score(y_test, pred)*100\n",
    "    recall = recall_score(y_test, pred)*100\n",
    "    f1_scores = f1_score(y_test, pred)*100\n",
    "    #accuracy = (tp + tn) / (tp + fp + tn + fn)*100\n",
    "    #precision = (tp) / (tp + fp)*100\n",
    "    #recall = (tp) / (tp + fn)*100\n",
    "    #f1_scores = (2 * precision * recall) / (precision + recall)\n",
    "    #plot_conf_metrics(y_test, pred)\n",
    "\n",
    "    sum_accuracy += accuracy\n",
    "    pred = enc.inverse_transform(pred)\n",
    "\n",
    "    fold_i += 1\n",
    "    acc.append(accuracy)\n",
    "    pr.append(precision)\n",
    "    rc.append(recall)\n",
    "    f1.append(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/MKNN_prediction.txt\", \"w\") as f:\n",
    "    mknn_predited_label ='\\n'.join(str(item) for item in pred)\n",
    "    f.write(mknn_predited_label)\n",
    "with open('output/jarak_ttg.txt', 'w') as g:\n",
    "    jarak = [nMin(k_value,map(float,i)) for i in jarak]\n",
    "    mknn_distance = '\\n'.join(str(ls) for ls in jarak)\n",
    "    g.write(mknn_distance)\n",
    "with open('output/index_ttg.txt', 'w') as j:\n",
    "    j.write('\\n'.join(str(a) for a in neigbor_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = pd.read_csv('output/MKNN_prediction.txt', names=['Sentiment'])\n",
    "jarak_pred = pd.read_csv('output/jarak_ttg.txt', names=['Distance'], sep='\\t')\n",
    "text_test = pd.read_csv('output/ResultX.txt', names=['text'])\n",
    "index_pred = pd.read_csv('output/index_ttg.txt', names=['Neigbor'])\n",
    "text_test = text_test.join(knn_pred)\n",
    "text_test = text_test.join(jarak_pred)\n",
    "text_test = text_test.join(index_pred)\n",
    "#text_test['Sentiment'] = text_test['Sentiment'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
    "text_test = text_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = pd.DataFrame(X_test)\n",
    "new_frame = new_frame.join(knn_pred)\n",
    "\n",
    "avg_acc = sum_accuracy/fold_n\n",
    "maxs = max(acc)\n",
    "mins = min(acc)\n",
    "res_df = pd.DataFrame({'iterasi':fol, 'Accuracy': acc, 'Precison':pr, 'Recall':rc, 'f1 score':f1})\n",
    "print(\"Avearge accuracy : \", str(\"%.4f\" % avg_acc)+'%')\n",
    "print(\"Max Score : \",str(maxs),\"in Fold : \", str(acc.index(maxs)+1))\n",
    "print(\"Min Score : \",str(mins), \"in Fold : \", str(acc.index(mins)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[['Accuracy', 'Precison', 'Recall', 'f1 score']].plot.line(title=\"Akurasi tiap Fold\")\n",
    "plot.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Algorithm K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_value = 9 # 1 - 25\n",
    "X = sentiment_result['text'].values\n",
    "y = sentiment_result['Sentiment'].values\n",
    "fold_i = 1\n",
    "fold_n = 10 # 3 5 7 10\n",
    "sum_accuracy = 0\n",
    "kfold = KFold(fold_n, shuffle=True, random_state=42)\n",
    "enc = LabelEncoder()\n",
    "fol = []\n",
    "acc, rc, pr, f1 = [], [], [], []\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    fol.append(fold_i)\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    svf = open('output/ResultX.txt', 'w')\n",
    "    sv_text = '\\n'.join(str(item) for item in X_test).replace(\"   \",\" \")\n",
    "    svf.write(sv_text)\n",
    "    svY = open ('output/y_train.txt', 'w')\n",
    "    svY.write('\\n'.join(str(item) for item in y_train))\n",
    "\n",
    "    #TFIDF\n",
    "    tf = TfidfVectorizer(decode_error=\"replace\")\n",
    "    X_train = tf.fit_transform(X_train)\n",
    "    X_test = tf.transform(X_test)\n",
    "    \n",
    "    y_train = enc.fit_transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "\n",
    "    # Algorithm\n",
    "    clf = KNeighborsClassifier(k_value)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    #tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    accuracy = accuracy_score(y_test, pred)*100\n",
    "    precision = precision_score(y_test, pred)*100\n",
    "    recall = recall_score(y_test, pred)*100\n",
    "    f1_scores = f1_score(y_test, pred)*100\n",
    "    #accuracy = (tp + tn) / (tp + fp + tn + fn)*100\n",
    "    #precision = (tp) / (tp + fp)*100\n",
    "    #recall = (tp) / (tp + fn)*100\n",
    "    #f1_scores = (2 * precision * recall) / (precision + recall)\n",
    "    #plot_conf_metrics(y_test, pred)\n",
    "\n",
    "    sum_accuracy += accuracy\n",
    "    pred = enc.inverse_transform(pred)\n",
    "\n",
    "    fold_i += 1\n",
    "    acc.append(accuracy)\n",
    "    pr.append(precision)\n",
    "    rc.append(recall)\n",
    "    f1.append(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/MKNN_prediction.txt\", \"w\") as f:\n",
    "    mknn_predited_label ='\\n'.join(str(item) for item in pred)\n",
    "    f.write(mknn_predited_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = pd.read_csv('output/MKNN_prediction.txt', names=['Sentiment'])\n",
    "text_test = pd.read_csv('output/ResultX.txt', names=['text'])\n",
    "text_test = text_test.join(knn_pred)\n",
    "#text_test['Sentiment'] = text_test['Sentiment'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
    "text_test = text_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tema money heist iya sayanga</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebel banget deh nonton film film bagus netfli...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norak banget nonton money heist spanyol seru b...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scene cctv polisi series money heist</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senin baca review money heist versi korea pena...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment\n",
       "0                      tema money heist iya sayanga   Negative\n",
       "1  sebel banget deh nonton film film bagus netfli...  Negative\n",
       "2  norak banget nonton money heist spanyol seru b...  Positive\n",
       "3              scene cctv polisi series money heist   Negative\n",
       "4  senin baca review money heist versi korea pena...  Negative"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avearge accuracy :  79.0500%\n",
      "Max Score :  85.0 in Fold :  2\n",
      "Min Score :  75.0 in Fold :  1\n"
     ]
    }
   ],
   "source": [
    "new_frame = pd.DataFrame(X_test)\n",
    "new_frame = new_frame.join(knn_pred)\n",
    "\n",
    "avg_acc = sum_accuracy/fold_n\n",
    "maxs = max(acc)\n",
    "mins = min(acc)\n",
    "res_df = pd.DataFrame({'iterasi':fol, 'Accuracy': acc, 'Precison':pr, 'Recall':rc, 'f1 score':f1})\n",
    "print(\"Avearge accuracy : \", str(\"%.4f\" % avg_acc)+'%')\n",
    "print(\"Max Score : \",str(maxs),\"in Fold : \", str(acc.index(maxs)+1))\n",
    "print(\"Min Score : \",str(mins), \"in Fold : \", str(acc.index(mins)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterasi</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precison</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>28.301887</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.378378</td>\n",
       "      <td>56.862745</td>\n",
       "      <td>65.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>42.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>80.5</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>42.372881</td>\n",
       "      <td>56.179775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>49.382716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.074074</td>\n",
       "      <td>32.786885</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>41.379310</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>75.5</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>37.288136</td>\n",
       "      <td>47.311828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>84.0</td>\n",
       "      <td>90.322581</td>\n",
       "      <td>49.122807</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>77.0</td>\n",
       "      <td>55.882353</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>45.238095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iterasi  Accuracy   Precison     Recall   f1 score\n",
       "0        1      75.0  55.555556  28.301887  37.500000\n",
       "1        2      85.0  78.378378  56.862745  65.909091\n",
       "2        3      78.0  80.000000  28.571429  42.105263\n",
       "3        4      80.5  83.333333  42.372881  56.179775\n",
       "4        5      79.5  68.965517  38.461538  49.382716\n",
       "5        6      76.0  74.074074  32.786885  45.454545\n",
       "6        7      80.0  80.000000  41.379310  54.545455\n",
       "7        8      75.5  64.705882  37.288136  47.311828\n",
       "8        9      84.0  90.322581  49.122807  63.636364\n",
       "9       10      77.0  55.882353  38.000000  45.238095"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.to_csv('hs.txt', index=False)\n",
    "res_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "575b1b4c9cb40b60b65888ca604b6df5d3b9d69fd4f2756bb0ac61f69d2ddd9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
